{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LAB0auYbkBL_"
   },
   "outputs": [],
   "source": [
    "#### This notebook was created to test Bert Masked Encoder to be used for Masked language model and the Seq4Rec using MultiHeadAttention Layer\n",
    "# 80% Replace with a [MASK] token: For 80% of the selected inputs the token is replaced with a [MASK] token similar to the classic cloze tests mentioned earlier.\n",
    "# 10% Replace with an incorrect word: For 10% of the selected inputs, the token is replaced by another randomly selected word whose only requirement is that itâ€™s different from the selected token.\n",
    "# 10% Replace with the correct word: The remaining 10% of the time the selected token is simply replaced with the correct token.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aI24KdzBzXSa"
   },
   "outputs": [],
   "source": [
    "### PARAMETER_LIST \n",
    "OUTPUT_LEN =256\n",
    "SEQUENCE_LEN =  256\n",
    "MAX_LEN = SEQUENCE_LEN\n",
    "EMBED_DIM = 128\n",
    "VOCAB_SIZE = 6000\n",
    "TOKEN_NUM = 30000\n",
    "N_NEURONS = 128\n",
    "NUM_HEADS = 8\n",
    "KEY_DIM = 128\n",
    "NUM_ATT_LAYER = 1\n",
    "SPECIAL_TOKENS=[\"[MASK]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b_Cbss_YzRtR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os \n",
    "import sys \n",
    "import re, string\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import Dense, TextVectorization, Embedding, MultiHeadAttention, Dropout,LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U61fUZkZzf2R"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_url = 'https://raw.githubusercontent.com/malinphy/datasets/main/IMDB_sent/IMDB%20Dataset.csv'\n",
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyk5iLK9X7M7",
    "outputId": "3de8d65e-98ae-4302-8de1-2d4cf1bac3ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-anwWQ9Izh2X"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = str(input_data).lower()\n",
    "    s = re.sub(\"<br />\", \" \",lowercase)\n",
    "    s = re.sub('\\x96|\\x85|\\xe3',' ',s) \n",
    "    out = re.sub('[%s]' % re.escape(string.punctuation), '', s)\n",
    "    return out\n",
    "\n",
    "df['review'] = df['review'].apply(custom_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "dFrekQLGi_6-",
    "outputId": "46963e49-85db-409f-c487-b1aa07df5ad7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-74114109-a299-45c7-a249-5863a5cb4931\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production   the filming te...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74114109-a299-45c7-a249-5863a5cb4931')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-74114109-a299-45c7-a249-5863a5cb4931 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-74114109-a299-45c7-a249-5863a5cb4931');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production   the filming te...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RZJ0k5EIi_1J"
   },
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "        max_tokens=VOCAB_SIZE,\n",
    "        output_mode=\"int\",\n",
    "        # standardize=custom_standardization,\n",
    "        output_sequence_length=SEQUENCE_LEN,\n",
    "    )\n",
    "vectorize_layer.adapt((df['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FDDCygEqi_sf"
   },
   "outputs": [],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab = vocab[0 : VOCAB_SIZE - len(SPECIAL_TOKENS)] + [\"[mask]\"]\n",
    "vectorize_layer.set_vocabulary(vocab)\n",
    "mask_token_id = vectorize_layer([\"[mask]\"]).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yld214muYC95"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N4vimrSGjE1l"
   },
   "outputs": [],
   "source": [
    "encoded_texts = vectorize_layer(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8-wr2R_ujEyI"
   },
   "outputs": [],
   "source": [
    "def get_masked_input_and_labels(encoded_texts):\n",
    "    # 15% BERT masking\n",
    "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
    "    # Do not mask special tokens\n",
    "    inp_mask[encoded_texts <= 2] = False\n",
    "    # Set targets to -1 by default, it means ignore\n",
    "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
    "    # Set labels for masked tokens\n",
    "    labels[inp_mask] = encoded_texts[inp_mask]\n",
    "\n",
    "    # Prepare input\n",
    "    encoded_texts_masked = np.copy(encoded_texts)\n",
    "    # Set input to [MASK] which is the last token for the 90% of tokens\n",
    "    # This means leaving 10% unchanged\n",
    "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
    "    encoded_texts_masked[\n",
    "        inp_mask_2mask\n",
    "    ] = mask_token_id  # mask token is the last in the dict\n",
    "\n",
    "    # Set 10% to a random token\n",
    "    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\n",
    "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
    "        3, mask_token_id, inp_mask_2random.sum()\n",
    "    )\n",
    "\n",
    "    # Prepare sample_weights to pass to .fit() method\n",
    "    sample_weights = np.ones(labels.shape)\n",
    "    sample_weights[labels == -1] = 0\n",
    "\n",
    "    # y_labels would be same as encoded_texts i.e input tokens\n",
    "    y_labels = np.copy(encoded_texts)\n",
    "\n",
    "    return encoded_texts_masked, y_labels, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IJN-8m5DjEuN"
   },
   "outputs": [],
   "source": [
    "bir, iki, uc =get_masked_input_and_labels(encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5iyHtM0DjEqR"
   },
   "outputs": [],
   "source": [
    "def get_pos_encoding_matrix(max_len, d_emb):\n",
    "    pos_enc = np.array(\n",
    "        [\n",
    "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
    "            if pos != 0\n",
    "            else np.zeros(d_emb)\n",
    "            for pos in range(max_len)\n",
    "        ]\n",
    "    )\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qjBpSB-jEmW",
    "outputId": "9f1b8cdb-0845-4510-8933-a02e0a123989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 833s 829ms/step - loss: 6.9974 - accuracy: 0.2412\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 830s 830ms/step - loss: 3.9692 - accuracy: 0.5520\n"
     ]
    }
   ],
   "source": [
    "first_input = tf.keras.Input(shape = (SEQUENCE_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE,EMBED_DIM)(first_input)\n",
    "position_embeddings = layers.Embedding(\n",
    "        input_dim=SEQUENCE_LEN,\n",
    "        output_dim=EMBED_DIM,\n",
    "        weights=[get_pos_encoding_matrix(SEQUENCE_LEN, EMBED_DIM)],\n",
    "        name=\"position_embedding\",\n",
    "    )(tf.range(start=0, limit=SEQUENCE_LEN, delta=1))\n",
    "# total_embs = word_embeddings + get_pos_encoding_matrix(SEQUENCE_LEN,EMBED_DIM)\n",
    "# total_embs = word_embeddings + position_embeddings\n",
    "x = embedding_layer + position_embeddings\n",
    "\n",
    "## number of the encoder layer determined with \n",
    "\n",
    "for i in range(NUM_ATT_LAYER):\n",
    "  ### number of attention heads determined according the NUM_HEADS\n",
    "  mha = MultiHeadAttention(num_heads = NUM_HEADS, key_dim = 16)(x,x,x)\n",
    "  norm_1 = LayerNormalization(epsilon=1e-6)(mha+x)\n",
    "\n",
    "  seq_model = tf.keras.Sequential([\n",
    "                                   Dense(N_NEURONS, activation = 'relu'),\n",
    "                                   Dense(EMBED_DIM)\n",
    "  ])\n",
    "\n",
    "  seq_layer = seq_model(norm_1)\n",
    "  norm_2 =LayerNormalization(epsilon=1e-6)(seq_layer+norm_1)\n",
    "  x = norm_2\n",
    "  print(i)\n",
    "\n",
    "top_layer = Dense(VOCAB_SIZE+1, activation='relu', name = 'selection_layer')(x)\n",
    "attention_model = tf.keras.Model(inputs = first_input, outputs = top_layer)\n",
    "tf.keras.utils.plot_model(\n",
    "    attention_model,\n",
    "    to_file='model.png', show_shapes=False, show_dtype=False,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n",
    "    layer_range=None, show_layer_activations=False\n",
    ")\n",
    "\n",
    "attention_model.compile(\n",
    "    loss = 'SparseCategoricalCrossentropy',\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    #  beta_1=0.9, beta_2=0.999, epsilon=1e-07\n",
    "     ),\n",
    "    metrics = ['accuracy']\n",
    "\n",
    ")\n",
    "\n",
    "attention_model.fit(bir,iki, epochs = 2, batch_size = 10)\n",
    "id2token = dict(enumerate(vectorize_layer.get_vocabulary()))\n",
    "token2id = {y: x for x, y in id2token.items()}\n",
    "sample_tokens = vectorize_layer([\"I have watched this [mask] and it was awesome\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zwBJvhrPjEiw"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# attention_model.save(\"drive/MyDrive/Colab Notebooks/bert_mlm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "YHQski67jEcb",
    "outputId": "19d4c288-1378-4144-b829-25305e8d2fe2"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0434ea32b36a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# \"prediction\": decode(tokens),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;34m\"probability\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;34m\"predicted mask token\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             }\n\u001b[1;32m     27\u001b[0m   \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0434ea32b36a>\u001b[0m in \u001b[0;36mconvert_ids_to_tokens\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mid2token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6000"
     ]
    }
   ],
   "source": [
    "def decode(tokens):\n",
    "        return \" \".join([id2token[t] for t in tokens if t != 0])\n",
    "\n",
    "def convert_ids_to_tokens(id):\n",
    "        return id2token[id]\n",
    "\n",
    "prediction = attention_model.predict(sample_tokens)\n",
    "\n",
    "masked_index = np.where(sample_tokens == mask_token_id)\n",
    "masked_index = masked_index[1]\n",
    "mask_prediction = prediction[0][masked_index]\n",
    "k=5\n",
    "top_indices = mask_prediction[0].argsort()[-k :][::-1]\n",
    "values = mask_prediction[0][top_indices]\n",
    "\n",
    "for i in range(len(top_indices)):\n",
    "  p = top_indices[i]\n",
    "  v = values[i]\n",
    "  tokens = np.copy(sample_tokens[0])\n",
    "  tokens[masked_index[0]] = p\n",
    "  result = {\n",
    "                \"input_text\": decode(sample_tokens[0].numpy()),\n",
    "                # \"prediction\": decode(tokens),\n",
    "                \"probability\": v,\n",
    "                \"predicted mask token\": convert_ids_to_tokens(p),\n",
    "            }\n",
    "  pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEm8ObEfC4-u",
    "outputId": "85476307-9cc3-4774-dac7-b8950a3bc7dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1CWPoIcC47X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuaHZNdIC41K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbYRzs7rC4xy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DD3HmZUC4um"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_MLM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
