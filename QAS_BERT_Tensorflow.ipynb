{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QAS_BERT_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBe+kpS+0gT0zmaMhgK/z6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malinphy/Embedding_calls/blob/main/QAS_BERT_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtgU0r1vmpYo"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os \n",
        "import sys \n",
        "import json\n",
        "from platform import python_version\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding,Dense,MultiHeadAttention\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "!pip install -q tensorflow-text\n",
        "\n",
        "import tensorflow_text as text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSd52L5Im4lv",
        "outputId": "e7f1a1a9-eab1-4492-eba3-7346c14d2d23"
      },
      "source": [
        "print('Python Version : ' ,python_version())\n",
        "print('tensorflow version : ', tf.__version__)\n",
        "print('pandas version : ', pd.__version__)\n",
        "print('numpy version : ', np.__version__)\n",
        "print('tf_hub version : ', hub.__version__)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Version :  3.7.10\n",
            "tensorflow version :  2.4.1\n",
            "pandas version :  1.1.5\n",
            "numpy version :  1.19.5\n",
            "tf_hub version :  0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmBrG2h5nNiH"
      },
      "source": [
        "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
        "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
        "with open(train_path) as f: raw_train_data = json.load(f)\n",
        "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "# max_seq_length = 384"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TEzyk13o3m_",
        "outputId": "18c90492-d16d-496d-fd2e-027c7517a255"
      },
      "source": [
        "print(raw_train_data.keys())\n",
        "print(raw_train_data['data'][0].keys())\n",
        "print(raw_train_data['data'][0]['title'][0:])\n",
        "print(raw_train_data['data'][1]['title'][0:])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'version'])\n",
            "dict_keys(['title', 'paragraphs'])\n",
            "University_of_Notre_Dame\n",
            "Beyonc√©\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZiT_Orho5up",
        "outputId": "4636727b-4337-41f9-a0b0-b573a54b385b"
      },
      "source": [
        "print(raw_train_data['data'][3]['paragraphs'][0].keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['context', 'qas'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAz7uKB1rpd2",
        "outputId": "ae4c6179-da1f-4200-f72c-708e5cced6e7"
      },
      "source": [
        "print(raw_train_data['data'][0]['paragraphs'][0]['qas'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}], 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'id': '5733be284776f41900661182'}, {'answers': [{'answer_start': 188, 'text': 'a copper statue of Christ'}], 'question': 'What is in front of the Notre Dame Main Building?', 'id': '5733be284776f4190066117f'}, {'answers': [{'answer_start': 279, 'text': 'the Main Building'}], 'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?', 'id': '5733be284776f41900661180'}, {'answers': [{'answer_start': 381, 'text': 'a Marian place of prayer and reflection'}], 'question': 'What is the Grotto at Notre Dame?', 'id': '5733be284776f41900661181'}, {'answers': [{'answer_start': 92, 'text': 'a golden statue of the Virgin Mary'}], 'question': 'What sits on top of the Main Building at Notre Dame?', 'id': '5733be284776f4190066117e'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-axDABlEPpa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "c9e7b5ea-cba3-4b25-c6bd-d861c65f20af"
      },
      "source": [
        "print(raw_train_data['data'][0]['title'])\n",
        "print(raw_train_data.keys())\n",
        "print(raw_train_data['data'][0].keys())\n",
        "print(raw_train_data['data'][0]['paragraphs'][0]['qas'][1]['answers'][0]['text'])\n",
        "x = (raw_train_data['data'][0]['paragraphs'][0]['context'])\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "University_of_Notre_Dame\n",
            "dict_keys(['data', 'version'])\n",
            "dict_keys(['title', 'paragraphs'])\n",
            "a copper statue of Christ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b_3Q4WXvI1X"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRU6qYM6w6vl"
      },
      "source": [
        "def text_maker (data):\n",
        "  squad_examples = []\n",
        "  full_context = []\n",
        "  full_question = []\n",
        "  full_answer = []\n",
        "  title = []\n",
        "  starting_index = []\n",
        "  for item in data[\"data\"]:\n",
        "    # full_context = []\n",
        "      title.append(item['title'])\n",
        "      for para in item[\"paragraphs\"]:\n",
        "          context = para[\"context\"]\n",
        "          full_context.append(context)\n",
        "          for qa in para[\"qas\"]:\n",
        "              question = qa[\"question\"]\n",
        "              full_question.append(question)\n",
        "              if \"answers\" in qa:\n",
        "                  answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                  full_answer.append(answer_text)\n",
        "                  all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                  start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                  # print(start_char_idx)\n",
        "                  starting_index.append(start_char_idx)\n",
        "                # squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
        "            # else:\n",
        "                # squad_eg = Sample(question, context)\n",
        "            # squad_eg.preprocess()\n",
        "            # squad_examples.append(squad_eg)\n",
        "\n",
        "  return(full_context, full_question, full_answer,starting_index,title)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He-c2Y4GxHNr"
      },
      "source": [
        "train_context, train_question,train_answer,train_answer_index,train_titles= text_maker(raw_train_data)\n",
        "test_context, test_question, test_answer,test_answer_index,test_titles = text_maker(raw_eval_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDtbzpfp3puq",
        "outputId": "a7b66074-8111-4ba0-e91b-81bfdeee769d"
      },
      "source": [
        "print('length of context', len(train_context))\n",
        "print('length of the question', len(train_question))\n",
        "print('length of the answers', len(train_answer))\n",
        "print('length of the index', len (train_answer_index))\n",
        "print('length of the title', len(train_titles))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of context 18896\n",
            "length of the question 87599\n",
            "length of the answers 87599\n",
            "length of the index 87599\n",
            "length of the title 442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rawCGNQ-8GUh"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJIaUhHWy5Zc"
      },
      "source": [
        "bert_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "bert_model = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHxpzNrKTei5"
      },
      "source": [
        "bert_preprocess_layer = hub.load(bert_preprocess)\n",
        "bert_layer = hub.KerasLayer(bert_model,trainable=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbkhX9ytzHqF"
      },
      "source": [
        "# text_test = ['this is such an amazing movie!']\n",
        "\n",
        "# sample_tokenizer = bert_preprocess_layer(text_test)\n",
        "# print(f'Keys       : {list(sample_tokenizer.keys())}')\n",
        "# print(f'Shape      : {sample_tokenizer[\"input_word_ids\"].shape}')\n",
        "# print(f'Word Ids   : {sample_tokenizer[\"input_word_ids\"][0, :12]}')\n",
        "# print(f'Input Mask : {sample_tokenizer[\"input_mask\"][0, :12]}')\n",
        "# print(f'Type Ids   : {sample_tokenizer[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UmenEbhi1n7Y",
        "outputId": "c9c63d59-6bfe-447b-9f51-6c1870e0d6f5"
      },
      "source": [
        "train_context[0]\n",
        "train_question[0]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULtbQBdMXcGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfca7de-cc82-41e4-c42c-66c455a62171"
      },
      "source": [
        "x = bert_preprocess_layer.tokenize(tf.constant(['I live in london']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe139051320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe139051320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTBTYVHyXt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f6967a-e88e-4a7c-b588-26b87564bdf2"
      },
      "source": [
        "bert_preprocess_layer.tokenize(['I live in london', 'I live in london'])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[1045], [2444], [1999], [2414]], [[1045], [2444], [1999], [2414]]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCdPIRI_yhl1"
      },
      "source": [
        "a = tf.constant(train_context[0])\n",
        "b = tf.constant(train_question[0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jb2OnXnypP2"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sosHxiRzG6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4f9802-4b60-4bcf-eae3-7c7ee850195c"
      },
      "source": [
        "bert_preprocess_layer.bert_pack_inputs([x,x])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe1390560e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe1390560e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int32)>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int32)>,\n",
              " 'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[ 101, 1045, 2444, 1999, 2414,  102, 1045, 2444, 1999, 2414,  102,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRj7JDM0cMd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shRQRr4G0EvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTp57X0H5bvc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2U0nXo_5iaR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clzangzr7o8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}