{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decomposed_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrfkcd9Sce3REnAgcQhQVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malinphy/Embedding_calls/blob/main/decomposed_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qrHtN6LTQ0v"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import tensorflow as tf \r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from dataclasses import dataclass\r\n",
        "from platform import python_version\r\n",
        "\r\n",
        "import re\r\n",
        "\r\n",
        "from dataclasses import dataclass\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import re\r\n",
        "from pprint import pprint"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy4xUtYTUG4S",
        "outputId": "9d518014-9cf7-4425-dc3f-46f305f881e9"
      },
      "source": [
        "print(\"python_version\", python_version())\r\n",
        "print('TensorFlow_version',tf.__version__)\r\n",
        "print('Pandas_version',pd.__version__)\r\n",
        "print('numpy_version',np.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python_version 3.6.9\n",
            "TensorFlow_version 2.4.0\n",
            "Pandas_version 1.1.5\n",
            "numpy_version 1.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "p1sCVP8RTivo",
        "outputId": "f3159d00-0f59-48bc-9d3f-3a6e67e63caa"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/malinphy/IMDB_Analysis_different_approachs/main/IMDB_Dataset_short2.csv'\r\n",
        "df = pd.read_csv(url)\r\n",
        "df.head(3)\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqFQhADLUmNO"
      },
      "source": [
        "# @dataclass\r\n",
        "# class Config:\r\n",
        "MAX_LEN = 256\r\n",
        "BATCH_SIZE = 32\r\n",
        "LR = 0.001\r\n",
        "VOCAB_SIZE = 30000\r\n",
        "EMBED_DIM = 128\r\n",
        "NUM_HEAD = 8  # used in bert model\r\n",
        "FF_DIM = 128  # used in bert model\r\n",
        "NUM_LAYERS = 1\r\n",
        "\r\n",
        "\r\n",
        "# config = Config()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c0c_1orU-Y5"
      },
      "source": [
        "def custom_standardization(input_data):\r\n",
        "    lowercase = tf.strings.lower(input_data)\r\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\r\n",
        "    return tf.strings.regex_replace(\r\n",
        "        stripped_html, \"[%s]\" % re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"), \"\"\r\n",
        "    )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdaZgy5OYiP2"
      },
      "source": [
        "var1 = custom_standardization(df['review'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5EJIPIJYlv2",
        "outputId": "2458d0ab-2135-4168-df48-4c821685ee1e"
      },
      "source": [
        "var1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(18999,), dtype=string, numpy=\n",
              "array([b'one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with me  the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word  it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far away  i would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side',\n",
              "       b'a wonderful little production   the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece   the actors are extremely well chosen michael sheen not only \"has got all the polari\" but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life   the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done',\n",
              "       b'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to love  this was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her \"sexy\" image and jumped right into a average but spirited young woman  this may not be the crown jewel of his career but it was wittier than \"devil wears prada\" and more interesting than \"superman\" a great comedy to go see with friends',\n",
              "       ...,\n",
              "       b'simply i just watched this movie just because of sarah  am also giving these 4 stars just because of heron the other side this movie was easily one of the worst movies i have ever seen theacting was horrible the script was uninspired this was a movie that kept contradicting itself the film was sloppy and unoriginal its not like i was expecting a good film just something to give me a jump or two this did not even do that   he worst thing is that the more i think about the overall plot the less sense it actually makes and the more holes we keep finding a real shame really as im fairly sure that there was a good idea lurking in there somewhere  im perhaps being a bit harsh giving the film a 410 but given the actors involved and again sara obvious writing talent this film really should have delivered far more',\n",
              "       b'this movie proves that good acting comes from good direction and this does not happen in ask the dust colin farrell is usually a fine actor but in this he is juvenile donald sutherland comes across as an amateur why because the script is awful the adaptation is awful and the actors seem bored and half hearted the atmosphere of the movie is bad  i could only think when it would finish and i turned it off half way the director has done a very poor job and even though i have not read the novel it is certainly a missed chance the atmosphere this film is trying to evoke and the message and storyline never reaches the audience in one word it is a terrible film',\n",
              "       b'omen iv 1991 was a bad madefortv movie since the 80s were over i guess the executives were experimenting in meth the drug of choice during the 90s because there is no other reason to explain this travesty why did they even bother making this a tv movie what were they mulling over when this one came up on the idea board did they even think for a second that this movie would catch on as perhaps they thought it could make it as a series well never know but i know one thing this movie was the major reason why i never bought the omen trilogy they should have knocked off a couple of bucks instead of putting out this \"extra\" disc  omen iv is basically a average american family remake of the first film instead of a snot nosed punk kid we get the spooky girl whos a total brat to everyone around her if the family had stronger parenting skills then none of the demonic events that have transpired in the past films would have never occurred these parents need to put their foot down and do some real discipline   not recommended best to avoid at all cost'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnHV1LcrYppD"
      },
      "source": [
        "def get_vectorize_layer(texts, vocab_size, max_seq, special_tokens=[\"[MASK]\"]):\r\n",
        "    \"\"\"Build Text vectorization layer\r\n",
        "\r\n",
        "    Args:\r\n",
        "      texts (list): List of string i.e input texts\r\n",
        "      vocab_size (int): vocab size\r\n",
        "      max_seq (int): Maximum sequence lenght.\r\n",
        "      special_tokens (list, optional): List of special tokens. Defaults to ['[MASK]'].\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        layers.Layer: Return TextVectorization Keras Layer\r\n",
        "    \"\"\"\r\n",
        "    vectorize_layer = TextVectorization(\r\n",
        "        max_tokens=vocab_size,\r\n",
        "        output_mode=\"int\",\r\n",
        "        standardize=custom_standardization,\r\n",
        "        output_sequence_length=max_seq,\r\n",
        "    )\r\n",
        "    vectorize_layer.adapt(texts)\r\n",
        "\r\n",
        "    # Insert mask token in vocabulary\r\n",
        "    vocab = vectorize_layer.get_vocabulary()\r\n",
        "    vocab = vocab[2 : vocab_size - len(special_tokens)] + [\"[mask]\"]\r\n",
        "    vectorize_layer.set_vocabulary(vocab)\r\n",
        "    return vectorize_layer\r\n",
        "\r\n",
        "var2  = get_vectorize_layer(var1,VOCAB_SIZE,MAX_LEN,[\"[MASK]\"])   "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Q5mpObZF5D"
      },
      "source": [
        "vectorize_layer = get_vectorize_layer(\r\n",
        "    var1,\r\n",
        "    # all_data.review.values.tolist(),\r\n",
        "    VOCAB_SIZE,\r\n",
        "    MAX_LEN,\r\n",
        "    special_tokens=[\"[mask]\"],\r\n",
        ")\r\n",
        "\r\n",
        "mask_token_id = vectorize_layer([\"[mask]\"]).numpy()[0][0]\r\n",
        "\r\n",
        "\r\n",
        "def encode(texts):\r\n",
        "    encoded_texts = vectorize_layer(texts)\r\n",
        "    return encoded_texts.numpy()\r\n",
        "\r\n",
        "var3 = encode(var1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKhJ0fvSZKhd"
      },
      "source": [
        "def get_masked_input_and_labels(encoded_texts):\r\n",
        "    # 15% BERT masking\r\n",
        "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\r\n",
        "    # Do not mask special tokens\r\n",
        "    inp_mask[encoded_texts <= 2] = False\r\n",
        "    # Set targets to -1 by default, it means ignore\r\n",
        "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\r\n",
        "    # Set labels for masked tokens\r\n",
        "    labels[inp_mask] = encoded_texts[inp_mask]\r\n",
        "\r\n",
        "    # Prepare input\r\n",
        "    encoded_texts_masked = np.copy(encoded_texts)\r\n",
        "    # Set input to [MASK] which is the last token for the 90% of tokens\r\n",
        "    # This means leaving 10% unchanged\r\n",
        "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\r\n",
        "    encoded_texts_masked[\r\n",
        "        inp_mask_2mask\r\n",
        "    ] = mask_token_id  # mask token is the last in the dict\r\n",
        "\r\n",
        "    # Set 10% to a random token\r\n",
        "    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\r\n",
        "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\r\n",
        "        3, mask_token_id, inp_mask_2random.sum()\r\n",
        "    )\r\n",
        "\r\n",
        "    # Prepare sample_weights to pass to .fit() method\r\n",
        "    sample_weights = np.ones(labels.shape)\r\n",
        "    sample_weights[labels == -1] = 0\r\n",
        "\r\n",
        "    # y_labels would be same as encoded_texts i.e input tokens\r\n",
        "    y_labels = np.copy(encoded_texts)\r\n",
        "\r\n",
        "    return encoded_texts_masked, y_labels, sample_weights"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AKvXPgabNTa",
        "outputId": "99542a92-873f-4cb1-a325-fe1de10cc0c6"
      },
      "source": [
        "var4 = get_masked_input_and_labels(var3)\r\n",
        "print(len(var4))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIvbUbKjcxcY",
        "outputId": "248383d7-7355-4ff0-c3a0-5a4032e08807"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZqtNsGsfYUJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}